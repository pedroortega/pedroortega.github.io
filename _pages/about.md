---
layout: about
title: about
permalink: /
subtitle: 

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info: 

news: true  # includes a list of news items
latest_posts: false  # includes a list of the newest posts
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

## Pedro A. Ortega
AGI and Cybernetics Researcher

## About

I was VP of research at **Kosen Labs** and prior to that, lead of the **Safety Analysis Team at DeepMind**. My research focuses on **artificial general intelligence** and the **formal principles of intelligence**, covering aspects such as learning, planning and decision making in both machines and biological organisms. My approach lies at the intersection between machine learning, computational neuroscience, theoretical economics, and physics.

## Research Interests

Most of my work centers on information-theoretic and statistical mechanical approaches to learning and control, leading to contributions in bounded rationality models and recasting adaptive control as a causal inference problem. I have also worked on causal induction, and on game- and decision-theoretic models in computational neuroscience. 

![Free energy](/assets/img/free-energy.png "The binary free energy functional. It's also meant to be a puzzling pic."){: style="display: block; margin: 0 auto" }

To get a sense of my work, please refer to:
  * my [PhD thesis](https://api.repository.cam.ac.uk/server/api/core/bitstreams/6946e54b-26d6-42f2-899a-6e31f6ebf07a/content) on bounded rationality and Bayesian control,
  * my paper on [Thompson sampling](https://arxiv.org/pdf/0810.3605.pdf) as Bayesian causal inference,
  * my paper on [bounded rationality](http://rspa.royalsocietypublishing.org/content/469/2153/20120683) through thermodynamic principles,
  * or my [publications](/publications).

I was part of the former **Tuebingen group on Sensorimotor Learning and Decision Making**, where some of the now widespread ideas on Thompson sampling, causality, and thermodynamic methods for reinforcement learning have originated. 
